\section*{Computational Complexity}
We will focus on decision problems. Other classes of problems that we will not explore are: Functional problems and optimization problems.\\
\begin{description}
    \item[Decision Problems] : $P: I \longrightarrow \left\{ yes, no \right\}$
    \item[Functional Problems] :
    \item[Optimization Problems] :
\end{description}
Having a fast (polynomial) solution for an optimization problems implies that i have a fast one also for the Functional version and the decision version of the problem. The same goes inversely with the decision being hard, complex (non polynomial).\\
The Computational model we will use is Turing Machines, read chapter 1 of the book.\\
\subsubsection*{Time Complexity}
This is a decision problem. There's a problem P, a class of models of computation M. The goal is to find in M the fastest machine m that solves P. By fastest we mean that executes least instructions. Fix a notion of dimension of the input which is usually done in the definition of the model of computation.\\
\textsc{Computational Church Turing Thesis:}\\
All reasonable models of computation are polynomially related. 
$$M_1: \Theta(f(n)) \leadsto M_2: \Theta (p(f(n))), \quad p \; polynomial$$
We know already about turing machines but now we'll introduce Unlimited registry machines (URM):\\
Has an infinite set of registers ($r_0, r_1, \ldots, r_n$), in any of these registers there can be an arbitrarily long natural number.
\begin{itemize}
    \item S(i) means that I sum 1 to the register i.
    \item Z(i) means that register i becomes 0.
    \item T(i,j) means that $r_j = r_i$.
    \item J(i,j,k) means that if the content of the $r_i = r_j$ jump to instruction k
\end{itemize}
Example:\\
P: compute x+1. For the turing machine this means receiving the binary digits of x and i want on output the result of x+1. The complexity is lineary with the number of digits.\\
With the URM the complexity is 1, i just need S(0). The problem is that we are hiding the size of the input so this model is not reasonable.\\
Let's make an addition to the URM model and add the instructions P(i)= $r_i = r_i*r_i$ we execute these instructions:
T(0,1), J(1,2,6), P(0), S(2), J(3,3,2) The output goes: $x, x^2, x^4, x^8, \ldots x^{2^x}$ with complexity $\Theta(n)$. With a turing machine only writing the digits of the output requires at least $\Theta: 2^xlog(x)$.\\
\textsc{Uniform complexity cost}:\\
Each instruction of the models has complexity $\Theta(1)$. This is not reasonable when we are using models involving operations that make the involved integers grow too fast. An example of this behaviour is the URM with the product operation.\\
\textsc{Logarithmic Complexity Cost}:\\
Each instruction of the models has complexity that depends on the number kof digits it manipulates.\\
It is fundamental to analyze the complexity of all the instructions in your computational model:
\begin{itemize}
    \item S(i): $r_i = r_i+1 \quad \Theta(log(r_i))$
    \item Z(i): $r_i = 0 \quad \Theta(1)$
    \item T(i,j): $\Theta(log(r_i))$
    \item J(i,j,k): $\Theta(min(log(r_i), log(r_j)))$
    \item P(i): $\Theta((log(r_i)^2))$
\end{itemize}
If we now analyze the cost of the models with the Logarithmic complexity cost we get that the URM and the Turing machine are related.\\
We define as $ P = \{L | L \text{can be decided in polynomial time on a deterministic Turing Machine}\} $. P is invariant with respect to the model of compuation ( conseguence of the extended Church tesis)
We recall that a configuration for a Turing machine with k tapes is in the form $(q,u_{1},w_{1}, \ldots,u_{k},w_{k})$. The initial configuration is always: $ (s,\triangleright, x, \triangleright,\sqcup, \ldots, \triangleright,\sqcup) $ and a final configuration is always: $ (H,u_{1},w_{1}, \ldots,u_{k},w_{k}) $ where $ H=\{\underbrace{yes,no} halt\} $. For a machine that solves a decision problem L: \[ 
    M(x) = yes\quad iff x\in L\\
    M(x) = yes\quad iff x \notin L
\]
For a machine that does not terminate on input x we write$ M(x) \uparrow $ and we say it diverges while the notation for a terminating TM is $ M(x) \downarrow $.\\
The notion of computation: a computation step for a machine M is a binary relationship between two configuration: \[ 
    (q, u_{1},w_{1}, \ldots,u_{k},w_{k}) \longrightarrow (q^{'},u_{1}^{'},w_{1}^{'}, \ldots,u_{k}^{'},w_{k}^{'})
\]
(For reference Papadimitriu section 2.1)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection*{Time Complexity}
Definition: \textsc{Time complexity}\\
Let M be a k-TM and x be an input for M we say that M on input x takes time t if: \[ 
    (s, \triangleright, x, \triangleright, \varepsilon, \ldots, \triangleright, \varepsilon) \longrightarrow ( H,\ldots) 
\] with $ H \in {yes, no, halt} $. We say that M operates in time at most $ f(n) $ if: \[ 
    \forall x with |x| = m \quad M on x takes time at most f(|x|) 
\]
We will say that a language $ L \in TIME(f(n)) iff \exists M k-TM$ and $M$ decides L and operates in time at most $f(n)$. $TIME(f(n)) = \{L, L', \ldots\} $\\
Example: L is the language of all strings that are palindromes. $ \Sigma = \{0,1\}\cup\{\sqcup, \triangleright\} $ we get $ \Theta(n^2) $\\\\
Example: M is a 2-TM we can solve the same problem in linear time. Is the quadratic loss shown here the worst possible loss between two TM machine models with different number of tapes?\\
\textsc{Theo 2.1 Papadimitriu}:\\
if M is a k-TM that decides a language L in time f(n), then there exists a 1-TM M' that decides L in time at most $ \Theta(f(n)^2) $. fundamental hypothesis is that f(n) >= n
\\
Papadimitriu 2.8.4
\[ 
    \forall n \exists x s.t. K(x) \geq l(x)
\]
Exercie 2.8.5\\
Show that the language of palindromes cannot be decided in $ \omega(n^2) $  less than quadratic time over a 1-TM. (look for Luca trevisan article about it). The idea: you take n = |x| and the string:
\[ 
    x_{1}, \ldots,x_{n}\underbrace{00000}{0}x_{n}, \ldots,x_{1}
\]
\begin{theorem}[Speedup Theorem 2.2]
    If $L \in TIME(f(n))$ , then \[ 
        \forall \epsilon > 0 L \in TIME(\epsilon \cdot f(n)+n +2) 
    \]
    The multiplicative constant in front of the higher degree term is dependant on the modal of computation.
    \begin{proof}
        hypothesis:
        $L \in TIME(f(n)) \rightarrow \exists M k-TM decides L in time f(n) $
        Goal, demonstrate
        \[ 
            \exists M' 2-TM decides L in time \varepsilon\cdots f(n) +n+2 
        \]
        M' has to simulate m steps of M with a constant number of steps (around 7 steps on M' are a macro-step of M') (m will depend on \varepsilon \leadsto \frac{7}{m}).\\
        M will make f(n) steps and the steps of M' will be 7 \cdot \frac{f(n)}{m}\\
        M in m steps can at most read and change m symbols on the tape. So if M' prime has to fit into a single step the m steps of the M machine, its alphabet will have to be $\Sigma ^m$. Each slot of the tape of M' contains an element of the alphabet $\Sigma^m$. M is doing m steps, how many slots of the machine M' can be modified/read during m steps of M? At most 2.\\
        In order to simulate the m steps of M the machine M' reads the current tuple, the one on the left and the one on the right and it stores the information on the state. Then it changes at most 2 of the tree tuples.\\
        The n additive term is because M' has to read the string x of M and encode it in blocks of m, finally it has to read the start symbol and blank space of the tape of M which are the 2 steps. Finally M' has to move back to its starting position so there are an additional \frac{n}{m} steps.\\
        TIME(f(n)) only makes sense with f(n) \geq n
    \end{proof}
\end{theorem}

\subsection*{Space Complexity}
 If we are not using an I\O machine the space used by M on input x is obtained by the configuration of the last step ( as we never delete the fact that we read a given character from the configuration). So it Is \[ 
    \sum_{i=1}^{k}{|u_i|+|w_i|} \geq |x| +c
\]
Recall the definition of I\O Turing Machines (cannot change input).