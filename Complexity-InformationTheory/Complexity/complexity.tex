\section{Computational Complexity}
Determining the complexity of a problem means giving bounds on the complexity of any possible algorithm for solving a problem.
We will focus on decision problems which is a class of problems for which the goal is to say, given an instance of the problem, if it has an answer or not. Other classes of problems that we will not explore are: Functional problems and optimization problems.\\
\begin{description}
    \item[Decision Problems] : 
    \item[Functional Problems] : 
    \item[Optimization Problems] :
\end{description}
Having a fast (polynomial) solution for an optimization problems implies that i have a fast one also for the Functional version and the decision version of the problem. The same goes inversely with the decision being hard, complex (non polynomial).\\
\subsubsection{Computation Model - Turing Machines}
The model of computation we are going to use to talk about computational complexity are Turing Machines which we are going to define here for ease of use.\\
\begin{definition}[Turing Machine]
    A Turing Machine is a quadruple $M= (K, \Sigma, \delta, s)$. Here K is a finite set of states; $s \in K$ is the initial state. $\Sigma$ is a finite set of symbols, we say $\Sigma$ is the alphabet of M. We assume that K and $\Sigma$ are disjoint sets. $\Sigma$ always contains the special symbols $\sqcup, \triangleright$: the blank and the first symbol o starting symbol. Finally $\delta$ is a transition function, which maps $K\times \Sigma$ to $(K \cup {h,"yes","no"})\times \Sigma \times {\leftarrow, \rightarrow,-- }$. We assume that h (the halting state), "yes" (the acceptin state), "no" (the rejecting state) and the cursor directions $\leftarrow, \rightarrow, --$, for "stay" are not in $K \cup \Sigma$. The function $\delta$ is the "program" of the machine. It specifies, for each combination of current state $q\in K$ and current symbol $\sigma \in \Sigma$, a triple $\delta(q,\sigma) = (p,\rho,D)$
\end{definition}
\begin{definition}[Configuration of a Turing Machine]
    We can define the operation of a Turing machine formally using the notion of a configuration. Intuitively, a configuration contains a complete description of the current state of the computation. Formally a configuration of M is a triple (q,u,w), where $ q \in K$ is a state, and $w,u$ are strings in $\Sigma^*$. $u$ is the string to the left of the cursor, including the symbol scanned by the cursor, and $u$ is the string to the right of the cursor, possibly empty. Finally q is the current state. 
\end{definition}

\subsubsection{Time Complexity}
This is a decision problem. There's a problem P, a class of models of computation M. The goal is to find in M the fastest machine m that solves P. By fastest we mean that executes least instructions. We need to fix a notion of dimension of the input which is usually done in the definition of the model of computation.\\
\begin{definition}[Time complexity for M TM, on input x]
    We say that M, Turing Machine, on input x has time complexity t if 
    \[ 
        (s,\triangleright, x) \underbrace{\longrightarrow}_{\text{t steps}} (H, w, u), \quad H\in {h,"yes","no"}
    \]
\end{definition}
\begin{definition}[Time complexity for M TM ]
    M has time complexity $f: \mathbb{N}\longrightarrow\mathbb{N}$ if:
    \[ 
        \forall x \in \Sigma^*\quad (s,\triangleright, x)\underbrace{\longrightarrow}_{\text{t steps}}(H,w,u) 
    \]
    with $t\leq f(|x|)$
    This definition is a worst case time complexity. 
\end{definition}
\subsubsection{URM}
We already know about turing machines but now we'll introduce Unlimited Registry Machines (URM):\\
Every URM has an infinite set of registers ($R_0, R_1, \ldots, R_n$), in any of these registers there can be an arbitrarily long natural number.
\begin{itemize}
    \item $S(i) \rightarrow R_i = R_i+1$.
    \item $Z(i) \rightarrow R_i = 0$.
    \item $T(i,j) \rightarrow R_j = R_i$.
    \item $J(i,j,k) \rightarrow if \;R_i = R_j$ jump to instruction k
\end{itemize}
Example, P:\\
Compute $x+1$. For the turing machine this means receiving the binary digits of $x$ and I want on output the result of $x+1$. The complexity is linear with the number of digits.\\
With the URM the complexity is 1, I just need $S(0)$. The problem is that we are hiding the size of the input so this model is not reasonable.\\
Let's make an addition to the URM model and add the instructions $P(i) \rightarrow R_i = R_i*R_i$ and we execute these instructions:
$T(0,1), J(1,2,6), P(0), S(2), J(3,3,2)$. The output goes: $x, x^2, x^4, x^8, \ldots x^{2^x}$ with complexity $\Theta(n)$. \\With a turing machine only writing the digits of the output requires at least $\Theta(2^xlog(x)) \leadsto \Omega(2^x) $.\\
\begin{definition}[Uniform complexity Cost]
    Each instruction of the models has complexity $\Theta(1)$. This is not reasonable when we are using models include operations that make the involved integers grow too fast. An example of this behaviour is the URM with the product operation.\\
\end{definition}
\begin{definition}[Logarithmic Complexity Cost]
    Each instruction of the models has complexity that depends on the number $k$ of digits it manipulates.\\
\end{definition}
It is clar that it's fundamental to analyze the complexity of all the instructions in your computational model. Let's do it for the URM model:
\begin{itemize}
    \item $S(i) \rightarrow R_i = R_i+1 \quad \Theta(log(R_i))$
    \item $Z(i) \rightarrow R_i = 0 \quad \Theta(1)$
    \item $T(i,j) \rightarrow R_j = R_i \quad \Theta(log(r_i))$
    \item $J(i,j,k) \rightarrow if \;R_i = R_j \text{ jump to instruction } k \quad \Theta(min(log(R_i), log(R_j)))$
    \item $P(i) \rightarrow R_i = R_i*R_i \Theta((log(R_i)^2))$
\end{itemize}
To decide when to use a Logarithmic criteria for computing the complexity cost I have to look for operations in the algorithm that in a polynomial number of steps makes the input grow exponentially, moreover these are used a number of times that depends on the size of the input.\\
If we now analyze the cost of the models with the Logarithmic complexity cost we get that the URM and the Turing machine are related.\\
\begin{thesis}[Computational Church Turing Thesis]
    All reasonable models of computation are polynomially related.
    \[ 
        M_1: \Theta(f(n)) \leadsto M_2: \Theta (p(f(n))), \quad p \; polynomial 
    \]
    In this case reasonable means that we have to use the logarithmic criteria.
\end{thesis}
We define as $ P = \{L | L \text{can be decided in polynomial time on a deterministic Turing Machine}\} $. P is invariant with respect to the model of compuation ( consequence of the extended Church tesis).
\subsubsection{Review of k-tape TM}
Later we'll now demonstrate that the loss in time complexity that we experience by moving from one reasonable model of computation to another is at most quadratic.\\
To show this result we reintroduce now some concepts about a k tape Turing Machine or k-TM. A configuration for a k-TM takes the following form
\[ 
    (q,w_1,u_1,w_2,u_2,\ldots,w_k,u_k),\quad w_i,u_i \in \Sigma^*
\]
Every $w_i$ is the string left of the cursor on k-th tape.\\ The initial configuration for a k-TM on input x is:
\[ 
     (s,\triangleright,x,\triangleright,\varepsilon,\triangleright,\varepsilon, \ldots,\triangleright,\varepsilon)
\]
A language $L\subseteq \Sigma^*$ is decided by a k-TM M if
\[ 
    \forall x \in \Sigma^* 
     \begin{cases}
        M(x) = "yes" & if \; x\in L \\
        M(x) = "no" & if \; x \notin L 
     \end{cases}
\]
A language $L\subseteq \Sigma^*$ is accepted by a k-TM M if
\[ 
    \forall x \in \Sigma^* 
     \begin{cases}
        M(x) = "yes" & if \; x\in L \\
        M(x)\uparrow & if \; x \notin L 
     \end{cases}
\]The difference is that a machine that accepts a language diverges if the input is not in the language. In fact, for a machine that does not terminate on input x we write$ M(x) \uparrow $ and we say it diverges while the notation for a terminating TM is $ M(x) \downarrow $.\\
The notion of computation: a computation step for a machine M is a binary relationship between two configuration: \[ 
    (q, u_{1},w_{1}, \ldots,u_{k},w_{k}) \longrightarrow (q^{'},u_{1}^{'},w_{1}^{'}, \ldots,u_{k}^{'},w_{k}^{'})
\]
(For reference Papadimitriu section 2.1)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Time Complexity}
\begin{definition}[Time complexity]
    Given M a k-TM and x the input for M, we say that M on input x takes time $t$ if
    \[ 
        (s, \triangleright, x, \triangleright, \varepsilon, \ldots, \triangleright, \varepsilon) \longrightarrow ( H,\ldots) 
    \] 
    with $ H \in {yes, no, halt} $. We say that M operates in time at most $ f(n) $ if: \[ 
    \forall x with |x| = m \quad M on x takes time at most f(|x|) 
    \]. Here $( H,\ldots)$ is short for final configuration.
\end{definition}
\begin{definition}[Time complexity classes]
    Given a language $L \subseteq \Sigma^*$, L is decidable in $ TIME(f(n))$ if and only if  $\exists k-TM M$ that decides L and operates in time at most $f(n)$.
    \[ 
        TIME(f(n)) = \left\{ L \mid L\subseteq \Sigma^* \exists M k-TM\; s.t. \; \text{M decides L in time } f(n) \right\} 
    \]
    Example: L is the language of all strings that are palindromes. $ \Sigma = \{0,1\}\cup\{\sqcup, \triangleright\} $ we get $ \Theta(n^2) $
\end{definition}
\subsubsection{Polynomial relationship between models of computation}
We can first start looking at this relationship by showing the time complexity for the problem of deciding the language of palindromes on a 1-TM and a k-TM. Here we summarize the program ideas:
\begin{description}
    \item[1-TM]: We suppose that the tape is originally $\triangleright, x_{1}, \ldots,x_{n}, \sqcup$. The machine starts reading the first character $x_1$, stores the information about the digit in its state, replaces $x_1$ with $\triangleright$ then moves right until it finds $\sqcup$. At this point it goes back one step and confronts the character from the state and the one under the cursror. If they match it goes back all the way to the new $\triangleright$ and starts over, otherwise it rejects.
    \item[k-TM]: Starting from the first character the machines reads the value and copies it on a different tape, all the way to $x_n$. After it copied all the input it moves back to the start on either of the tape and starts moving one cursor forward and one backwards meanwhile checking for matching character at every step.
\end{description}

\begin{theorem}[Theorem 2.1 Papadimitriu]:\\
Given M a k-TM that operates in time f(n), then there exists a 1-TM M' operates in time at most $ \Theta(f(n)^2) $ such that $\forall x \quad M(x) =M'(x)$. Fundamental hypothesis is that $f(n)\geq n$
\begin{proof}
    For the sake of brevity we'll only give the idea for the proof. Basically M' has to mimic the k tapes of M with it's only tape. To do that we specify an alphabet that is $\Sigma \cup \munderbar{\Sigma} \cup \left\{ \triangleright', \triangleleft \right\}$. We will use the underlined characters to store the information of where is the cursor on the k-th tape of the machine M and the special starting symbol will be use to delimit the start of every k-th string, meanwhile the $\triangleleft$ delimits the end of each k-th "tape".\\
    To perform any steps of M, M' will have to scan the entire tape once to store in its state the information about every symbol under the k-th cursor and once more to perform the necessary modifications, needing in total 4 traversals of the entire tape. Particular attention must be given to the case in which the k-th cursor is on the last symbol of its sub-tape and wants to move to the right. To allow for such a move we must shift the entire string starting by marking the tape end symbol with an underbar $\munderbar{\triangleleft}$, then going all the way to the end of the tape of M' and shifting every character one position. We can now move back to $\munderbar{\triangleleft}$, move it to the right as $\triangleleft$ and placing $\sqcup$ in its previous position.
\end{proof}
\end{theorem}

%
%Papadimitriu 2.8.4
%\[ 
%    \forall n \exists x s.t. K(x) \geq l(x)
%\]
%Exercie 2.8.5\\
%Show that the language of palindromes cannot be decided in $ \omega(n^2) $  less than %quadratic time over a 1-TM. (look for Luca trevisan article about it). The idea: you take n %= |x| and the string:
%\[ 
 %   x_{1}, \ldots,x_{n}\underbrace{00000}{0}x_{n}, \ldots,x_{1}
%\]

\begin{theorem}[Speed-up Theorem ]
    If $L \in TIME(f(n))$ , then \[ 
        \forall \epsilon > 0,\quad \exists L \in TIME(\epsilon \cdot f(n)+n+2) 
    \]
    The multiplicative constant in front of the higher degree term is dependant on the model of computation.
    \begin{proof}
        Idea: M' will have to process many digits in a signle "macro" step to reduce the mulitplicative constants.
        Hypothesis:\\
        $L \in TIME(f(n)) \rightarrow \exists M k-TM$ decides L in time $f(n)$
        Demonstration:\\
        \[ 
            \exists M'\; 2-TM\; \text{ decides L in time } f'(n)=\varepsilon \cdot f(n)+n+2, \quad \forall \varepsilon >0
        \]
        $M'$ has to simulate $m$ steps of $M$ with a constant number of steps (around 6 steps on $M'$ constitute a macro-step of $M'$) ($m$ will depend on $\varepsilon \leadsto \frac{7}{m})$.\\
        $M$ will make $f(n)$ steps to complete the computation while the steps of $M'$ will be $6 \cdot \frac{f(n)}{m}$\\
        $M$ in $m$ steps can at most read and change $m$ symbols on the tape. So if $M'$ prime has to fit into a single step the $m$ steps of the $M$ machine, its alphabet will have to be $\Sigma^m$.This means that we will encode $m$ symbols of the alphabet of M into a single symbol of the alphabet of M'\\
        Each slot of the tape of $M'$ contains an element of the alphabet $\Sigma^m$.\\
        A key point is to understande that $M$ with $m$ steps can at most change slots of its tape that were grouped into 2 different slots of the $M'$ machine.\\
        At the beginning of the computation $M'$ reads the input x and encodes it into tuples of $\Sigma^m$.
        In order to simulate the $m$ steps of $M$ the machine $M'$ reads the current tuple, the one on the left and the one on the right and it stores that information on the state. Then it changes at most 2 of the three tuples.\\The multiplicative constant 6 comes from the number of moves $M'$ has to make (these can be optimized):
        \begin{itemize}
            \item Read the information on the starting tuple and store it in the state and move to the left
            \item Read the information and store it in the state and move back to the starting tuple
            \item Move to the right tuple 
            \item Read the information and store it in the state, move back to the starting tuple
            \item Change the symbol on the tape and move to either the right or left tuple
            \item Change the symbol on the tape 
        \end{itemize}
        The $n$ additive term is because $M'$ has to read the string x of $M$ and encode it in blocks of $m$, and it has to read the start symbol and blank space of the tape of $M$ which are the 2 steps. Finally $M'$ has to move back to its starting position so there are an additional $\frac{n}{m}$ steps.\\
        $TIME(f(n))$ only makes sense with $f(n) \geq n$
    \end{proof}
\end{theorem}

\subsection{Space Complexity}
 If we are not using an I\O machine the space used by M on input x is obtained by the configuration of the last step ( as we never delete the fact that we read a given character from the configuration). So it Is \[ 
    \sum_{i=1}^{k}{|u_i|+|w_i|} \geq |x| +c
\]
Recall the definition of I\O Turing Machines (cannot change input).
M k-tm over x takes space $ \sum_{i=1}^{k}{|w_i|+|u_i|} $
where the $w_i$ and $u_i$ are the ones from the last layer.
Different consideration, if M is a i/o turing machine the space is $\sum_{i=2}^{k-1}{|w_i|+|u_i|}$. M which is an i/o k-tm decides L in space complexity f(n) if $\forall x : |x|=n \; M(x)\downarrow \;$ using space ad most $f(n)$. The language L belongs to the class $L \in SPACE(f(n)) \; iff \; \exists M i/o TM $ that decies L in space $f(n)$. i/o turing machines are linearly related to a generic k-tm turing machine so we'll use i/o machines to talk and determin space complexity and generic k-tm turing machines for time complexity. (proof not needed)There's also speed up theorem for space.
\begin{theorem}[space speed up]
    $L \in SPACE(f(n)) : \forall \varepsilon >0 \; L \in SPACE(\varepsilon\cdot f(n) +2)$
\end{theorem}
\subsection*{RAM computational model}
RAM stands for Random Access Machine. It is made of an infinite set of work registers, the content of $r_i$ can be arbitrarily large. Moreover there are more registers with arbitrarily large integers and they are the input registers. Its program ( $P=(\pi_{1}, \ldots,\pi_{n})$ ) is a finite set of instructions taken from the set:
\begin{description}
    \item[READ J]: $r_0 = i_j$
    \item[READ $\uparrow$j] = $r_0 = i_{r_j}$
    \item[STORE J] = $r_j = r_0$
    \item[STORE $\uparrow$ j]  $r_{r_j}=r_0$
    \item[LOAD J] $r_0 = r_j$
    \item[LOAD $\uparrow$ j] $r_0 = r_{r_j} $
    \item[LOAD =j] $r_0 = j$
    \item[ADD] $r_0 = r_0+r_j$
    \item[ADD $\uparrow$ j] $r_0 = r_0+r_{r_j}$
    \item[ADD =j]    $r_0 = r_0+j$
    \item[SUB] $r_0 = r_0-r_j$
    \item[SUB $\uparrow$ j] $r_0 = r_0-r_{r_j}$
    \item[SUB =j]    $r_0 = r_0-j$
    \item[HALF] $r_0 = \left\lfloor \frac{r_0}{2} \right\rfloor$
    \item[JUMP j] $k = j$, (k is the program counter) 
    \item[JPOS j] if $r_0>0 $then $k = j$
    \item[JNEG j] if $r_0<0$ then $k = j$
    \item[JZERO j] if $r_0=0$ then $k = j$
    \item[HALT] $k=0$
\end{description}
Operational semantics: the meaning of a program is a graph with a starting configuration and a relationship between a different configuration.\\
denotational semantics: you map the program to the function computed by P, static verification tecniques, abstract interpretation. Optional study reference Robin Milner Calculus of communication systems\\
\begin{definition}[RAM configuration]
    Given a RAM P, to define its configuration we need the couple:
    \[ 
        C=(k,R) 
    \]
    where k is the program counter and R is the set of working and index regsiters with their content
    \[ 
        R = \left\{ (R_{j1}, r_{j1}), \ldots,(R_{jn}, r_{jn}) \right\} 
    \]
\end{definition}
and a configuration step: 
\[ 
    (k, R) \overset{P,I}{\longrightarrow} ( k', R') 
\]
Defintion of computation step with many cases:
For instance the program P is $P=(\pi_{1}, \ldots,\pi_{n})$ and the instruction $\pi_k = ADD j$ and $R={(R_{j1}, r_{j1}), \ldots,(R_{jh }, r_{jh}}$ from the configuration \[ 
    (k, R) \overset{P,I}{\longrightarrow} ( k+1,(R\setminus\{(R_0,r_0)\}\cup \{(R_0, r_0+r_j)\}) )
\]
To shorten the fact that we compute k steps we write: $\overset{P, I^k}{\longrightarrow}$\\
Function computed by a RAM P
\[ 
    \phi : D \longrightarrow \mathbb{N} ,\quad D \subseteq \mathbb{N}^h 
\]
\[ 
    \forall I \in D, \quad (1, \emptyset) \overset{P,I^\ell}{\longrightarrow} (0, R) 
\]with $(\underset{R_0}{0},\phi(I)) \in R$\\
P on input I takes time $t$ if $(1, \emptyset) \overset{P,I^t}{\longrightarrow} (0,R)$\\
P operates in time $f(n)$ if $\forall I: l(I) = n $ P on I takes time $f(n)$ where $l(I) = \sum_{j=1}^{h}{l(i_j)}$ where $l(i_j)$ is the number of bits of that integer $i_j$.\\\\
Simulation of a TM with a RAM:\\
SInce the RAM only operates on integer we have to encode the alphabet of the TM into integers.
\[ 
    D_{\Sigma}= \{(i_i,\ldots, i_n,0) | n\geq 0 \forall 1\leq j\leq n \quad 1 \leq i_j\leq l,  \} 
\]
M decides $L \subseteq \Sigma^*$, while a RAM P simulates the Turing machine M (that decides L) if P computes the function  \[ 
    \phi_L : D_{\Sigma} \longrightarrow \mathbb{N}
\]where \[ 
    \phi_L : (i_{1}, \ldots,i_{n}, 0) = \begin{cases}
        0 & \sigma_{1}, \ldots,\sigma_{n} \notin L\\
        1 & \sigma_{1}, \ldots,\sigma_{n} \in L  
    \end{cases} 
\]
