\section*{Complexity}
    \subsection*{Kolmogorov}
        \subsubsection*{History}
        We've talked about Shannon who worked in the US, studied at MIT and Princeton, collaborated with Bell Labs.
        We've talked about Fano who started at the Politecnico di Torino and then moved to MIT.
        Then we talked about Huffman who worked at Ohio State University, then founds the University of California Santa Cruz.\\
        Kolmogorov, unlike the other names we've seen so far, does not come from the west. In 1965 he was working at the University of Moscow\\
        \subsubsection*{Idea}
        Consider a computational model and define the complexity of a string as the lenght of the shortest program (in that computational model)
        that can generate that string. We'll use Turing Machines: $m = (k, \Sigma,\delta, s)$
        \begin{description}
            \item[k]: finite set of states
            \item[$\Sigma$]: finite alphabet\quad  $\triangleright, \sqcup \in \Sigma$
            \item[$\delta$]: $K \times \Sigma \longrightarrow (K\cup\{yes, no, halt\}) \times  \Sigma \times \left\{\rightarrow, \leftarrow, -\right\}$
            \item[s]: $s \in K$ start state
        \end{description}
    \subsubsection*{Church-Turing Thesis}
    All computational models are turing-equivalent.\newline
    Turing machines with k tapes and I/O
    $m=(K,\Sigma, \delta, s)$
    \begin{itemize}
        \item $\delta: \Sigma^k x K \rightarrow \Sigma^k x (K \cup {yes, no, halt}) x \left\{ \rightarrow, \leftarrow, - \right\}^k$
        \item The input tape (1st tape) cannot be modified but we can move backwards as much as possible
        \item The output tap (last tape) can only go forwards
    \end{itemize}
    \subsubsection*{Universal Machine Theorem}
    $$\exists u, u \text{Universal Turing Machine} | u(bin(m), x) = m(x)$$
    How does the universal turing machine works:
    its tape is somethink like this: start $ \left[ 01\ldots 1010 \right] $ x
    To be able to go on with the computation if we were in the middle of it, we need to know the configuration of the machine.
    The configuration is stored in one of the k tapes. We also need the state we are on and the position of the first tape.
    The tape and the position can be expressed as a triple $(q, w, \varsigma)$
    \begin{itemize}
        \item q is the current character
        \item w is the string left of q
        \item $\varphi $is the string right of q
    \end{itemize}
    The Kolmogorov complexity of a string m is denoted by $K_u(x) = \underset{u(bin(m))=x}{min}|bin(m)|$
    \subsubsection*{Observation}
    Unfortunately this notion is not computable. $$
    \nexists\; A\quad \text{Turing Machine} \quad|\quad A(x) = K_u(x)$$
    \subsubsection*{Conditional Kolmogorov Complexity}
    The Conditional Kolmogorov Complexity of x given y is:
    $$ K_u(x|y) = \underset{u(bin(m),y)=x}{min} |bin(m)| $$
    This means that, obviously, if we provied some more information $K_u(x|y) \leq K_u(x)$. One of the most common information given is $|x|$.\\
    How does the CKC change if we change universal machine?
    $$A \text{Universal Turing Machine}, U \text{Universal Turing Machine}$$
    $$K_U(x|y)\;?? \; K_A(x|y)$$
    To answer we can think:
    $U(bin_U(A), bin_A(m),y)=x$, $K_u(x|y) \leq K_A(x|y)+c_A$
    Study reference for this part is taken from: 
    \begin{itemize}
        \item Elements of Information Theory, Cover-Thomas, chapter 8
        \item An introduction to Kolmogorov Complexity and its applications, M. Li and P. Vitanyi
    \end{itemize}
    \subsubsection*{Invariance of Kolmogorov Complexity}
    $$\forall x \quad |K_U(x)- K_A(x)| \leq c,\; c \;\text{constant}$$
    \subsubsection*{Theorem}
    $$ K(x) \leq |x| +c, \text{Li, Vitanyi}$$
    \subsubsection*{Proof}
    $U\; \text{Printing Universal Turing Machine}$, we add a bit of information:
    if the first digit of the input tape is 0, then it simulates the rest of the tape as it is a binary encoding of a turing machine.
    Else if the first digit is 1 the machine will print in output the remaining significant digits ( not blank ).
    \subsubsection*{Proposition}
    The number of strings having Kolmogorov complexity $< h$ is $< 2^h$\\
    Proof:\\
    $$2 \leadsto 1, 2^2 \leadsto 2 \ldots $$
    $$2^0 + 2^1+ \ldots + 2^{h-1}= 2^{h}-1$$
    These are the machines that can have a binary encoding of lenght at most $h-1$
    \subsubsection*{Corollary}
    There is at least one string x such that $K(x)\leq|x|$\\
    Proof: For a given h 
    $$\text{at most } 2^{h}-1 \text{ strings with KC} < h$$
    There are $2^h$ strings of lenght h. At least 1 string of lenght h has a KC $\geq$ h
    $$ \forall x \quad K(x) \leq |x|+c$$
    $$\exists x \quad K(x) \geq |x|$$

    \subsubsection*{Kolmogorov Encoding}
    $$\varphi_K(x) = bin(m)\quad\text{U.D.}$$
    $$\varphi_k: A* \longrightarrow \left\{ m | m \text{Turing Machine} \right\}$$
    $\varphi_k(x)$ is the shortest machine that produces bin(x). This encoding is not computable but it's UD.
    The Kolmogorov complexity is then: $K(x) = |\varphi_k(x)|$.
    $$\underset{E_n(K(x))}{EL_n(\varphi_k)} = \sum_{x\in A^n}{p(x)\underset{K(x)}{|\varphi_k(x)|}}$$
    $$EL_n(\varphi_k) \geq \mathbb{H}(P^n) = n\mathbb{H}(P)$$
    where P is the probability distribution over A. The first partial result then is: 
    $$\frac{E_n(K(x))}{n} \geq \mathbb{H}(P)$$
    To set a bound from the other side we reason as follows: any U.D. code $\varphi$ can be seen as a set of machines for producing strings. \{Decoder $\varphi$ ; $\varphi(x)$ \} is an algorithm that produces x as output.
    $$\forall x\quad K(x) \leq |Decoder(\varphi)|+|\varphi(x)|$$
    If applied to Shannon Code:
    \begin{align*}
        E_n(K(x)) &\leq |Decoder \varphi|+ \sum_{x\in A^n}{p(x)|\varphi(x)|}\\
        & \leq |Decoder \varphi| + EL_n(\varphi)\\
        & \underset{Shannon\;C.}{\leq} |Decoder \varphi| + \mathbb{H}(P^n)+1 \quad \text{Shannon Un-optimality}\\
        & =|Decoder \varphi| + n\mathbb{H}(P)+1\\
        & \leq K(P) + n\mathbb{H}(P)+1
    \end{align*}
    $$\frac{E_n(K(x))}{n} \leq \frac{K(P)}{n}+ \mathbb{H}(P)+\frac{1}{n}$$
    
    

